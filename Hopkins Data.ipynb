{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyGithub\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/f4/0dbe960b829266eb01034b6d82cb423b3e88291d35d901bc8504f2e7a4b9/PyGithub-1.46-py3-none-any.whl (205kB)\n",
      "Collecting pyjwt\n",
      "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.14.0 in c:\\users\\brian\\anaconda3\\lib\\site-packages (from PyGithub) (2.22.0)\n",
      "Collecting deprecated\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\brian\\anaconda3\\lib\\site-packages (from requests>=2.14.0->PyGithub) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\brian\\anaconda3\\lib\\site-packages (from requests>=2.14.0->PyGithub) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\brian\\anaconda3\\lib\\site-packages (from requests>=2.14.0->PyGithub) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brian\\anaconda3\\lib\\site-packages (from requests>=2.14.0->PyGithub) (2019.9.11)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\brian\\anaconda3\\lib\\site-packages (from deprecated->PyGithub) (1.11.2)\n",
      "Installing collected packages: pyjwt, deprecated, PyGithub\n",
      "Successfully installed PyGithub-1.46 deprecated-1.2.7 pyjwt-1.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyGithub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "import os\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"github.txt\") as myfile:\n",
    "    firstNlines=myfile.readlines()[0:2]\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Github(firstNlines[0].strip(), firstNlines[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo=g.get_repo('CSSEGISandData/COVID-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = repo.get_contents(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContentFile(path=\"csse_covid_19_data\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sha_for_tag(repository, tag):\n",
    "    \"\"\"\n",
    "    Returns a commit PyGithub object for the specified repository and tag.\n",
    "    \"\"\"\n",
    "    branches = repository.get_branches()\n",
    "    matched_branches = [match for match in branches if match.name == tag]\n",
    "    if matched_branches:\n",
    "        return matched_branches[0].commit.sha\n",
    "\n",
    "    tags = repository.get_tags()\n",
    "    matched_tags = [match for match in tags if match.name == tag]\n",
    "    if not matched_tags:\n",
    "        raise ValueError('No Tag or Branch exists with that name')\n",
    "    return matched_tags[0].commit.sha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_directory(repository, sha, server_path):\n",
    "    \"\"\"\n",
    "    Download all contents at server_path with commit tag sha in\n",
    "    the repository.\n",
    "    \"\"\"\n",
    "    contents = repository.get_contents(server_path, ref=sha)\n",
    "\n",
    "    for content in contents:\n",
    "        print(\"Processing %s\" % content.path)\n",
    "        if content.type == 'dir':\n",
    "            download_directory(repository, sha, content.path)\n",
    "        else:\n",
    "            try:\n",
    "                path = content.path\n",
    "                file_content = repository.get_contents(path, ref=sha)\n",
    "                file_data = base64.b64decode(file_content.content).decode('ascii')\n",
    "                file_out = open(content.name, \"w\")\n",
    "                file_out.write(file_data)\n",
    "                file_out.close()\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sha = get_sha_for_tag(repo, 'master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/.gitignore\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/01-22-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/01-23-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/01-24-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/01-25-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/01-26-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/01-27-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/01-28-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/01-29-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/01-30-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/01-31-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-01-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-02-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-03-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-04-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-05-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-06-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-07-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-08-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-09-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-10-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-11-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-12-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-13-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-14-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-15-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-16-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-17-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-18-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-19-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-20-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-21-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-22-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-23-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-24-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-25-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-26-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-27-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-28-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/02-29-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/03-01-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/03-02-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/03-03-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/03-04-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/03-05-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/03-06-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/03-07-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/03-08-2020.csv\n",
      "Processing csse_covid_19_data/csse_covid_19_daily_reports/README.md\n"
     ]
    }
   ],
   "source": [
    "download_directory(repo, sha, 'csse_covid_19_data/csse_covid_19_daily_reports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\brian\\projects\\COVID-19\\csse_daily_reports\\02-01-2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = r'C:\\Users\\brian\\projects\\COVID-19\\csse_daily_reports\\\\'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_non_zero_file(fpath):\n",
    "    return os.path.isfile(fpath) and os.path.getsize(fpath) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_files = []\n",
    "for file in onlyfiles:\n",
    "    if is_non_zero_file(mypath + file) and file[-3:]=='csv':\n",
    "        nonzero_files.append(mypath + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-01-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-02-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-03-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-04-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-05-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-06-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-07-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-08-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-09-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-10-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-11-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-12-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-13-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-14-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-15-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-16-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-17-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-18-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-19-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-20-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-21-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-22-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-23-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-24-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-25-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-26-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-27-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-28-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\02-29-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\03-01-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\03-02-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\03-03-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\03-04-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\03-05-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\03-06-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\03-07-2020.csv',\n",
       " 'C:\\\\Users\\\\brian\\\\projects\\\\COVID-19\\\\csse_daily_reports\\\\\\\\03-08-2020.csv']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for file in nonzero_files:\n",
    "    df_1 = pd.read_csv(file)\n",
    "    df_1['filename'] = file[-15:]\n",
    "    df_list.append(df_1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3754 entries, 0 to 3753\n",
      "Data columns (total 9 columns):\n",
      "Confirmed         3754 non-null int64\n",
      "Country/Region    3754 non-null object\n",
      "Deaths            3754 non-null int64\n",
      "Last Update       3754 non-null object\n",
      "Latitude          1429 non-null float64\n",
      "Longitude         1429 non-null float64\n",
      "Province/State    2359 non-null object\n",
      "Recovered         3754 non-null int64\n",
      "filename          3754 non-null object\n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 264.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Last Update'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Latitude', 'Longitude'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Diamond Princess'] = df['Province/State'].str.contains('Diamond Princess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Date</th>\n",
       "      <th>Diamond Princess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-21T23:03:13</td>\n",
       "      <td>From Diamond Princess</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-21 23:03:13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>1</td>\n",
       "      <td>Israel</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-21T15:33:03</td>\n",
       "      <td>From Diamond Princess</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-21 15:33:03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>7</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-22T17:03:05</td>\n",
       "      <td>From Diamond Princess</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-22 17:03:05</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1</td>\n",
       "      <td>Israel</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-22T20:53:02</td>\n",
       "      <td>From Diamond Princess</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-22 20:53:02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>8</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-27T03:33:06</td>\n",
       "      <td>From Diamond Princess</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-27 03:33:06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-29T02:03:10</td>\n",
       "      <td>From Diamond Princess</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-29 02:03:10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Confirmed Country/Region  Deaths          Last Update  \\\n",
       "1499          4      Australia       0  2020-02-21T23:03:13   \n",
       "1518          1         Israel       0  2020-02-21T15:33:03   \n",
       "1580          7      Australia       0  2020-02-22T17:03:05   \n",
       "1602          1         Israel       0  2020-02-22T20:53:02   \n",
       "2037          8      Australia       0  2020-02-27T03:33:06   \n",
       "2321          0      Australia       0  2020-02-29T02:03:10   \n",
       "\n",
       "             Province/State  Recovered                Date Diamond Princess  \n",
       "1499  From Diamond Princess          0 2020-02-21 23:03:13             True  \n",
       "1518  From Diamond Princess          0 2020-02-21 15:33:03             True  \n",
       "1580  From Diamond Princess          0 2020-02-22 17:03:05             True  \n",
       "1602  From Diamond Princess          0 2020-02-22 20:53:02             True  \n",
       "2037  From Diamond Princess          0 2020-02-27 03:33:06             True  \n",
       "2321  From Diamond Princess          0 2020-02-29 02:03:10             True  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Province/State']=='From Diamond Princess']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['filename'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2106 entries, 0 to 3741\n",
      "Data columns (total 8 columns):\n",
      "Confirmed           2106 non-null int64\n",
      "Country/Region      2106 non-null object\n",
      "Deaths              2106 non-null int64\n",
      "Last Update         2106 non-null object\n",
      "Province/State      1435 non-null object\n",
      "Recovered           2106 non-null int64\n",
      "Date                2106 non-null datetime64[ns]\n",
      "Diamond Princess    1435 non-null object\n",
      "dtypes: datetime64[ns](1), int64(3), object(4)\n",
      "memory usage: 148.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Province/State'] = df['Province/State'].str.replace(' \\(From Diamond Princess\\)', '').replace('None', 'From Diamond Princess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hubei', 'Zhejiang', 'Guangdong', 'Henan', 'Hunan', 'Anhui',\n",
       "       'Jiangxi', 'Chongqing', 'Sichuan', 'Shandong', 'Jiangsu',\n",
       "       'Shanghai', 'Beijing', 'Fujian', 'Shaanxi', 'Guangxi', 'Hebei',\n",
       "       'Yunnan', 'Heilongjiang', 'Liaoning', 'Hainan', 'Shanxi',\n",
       "       'Tianjin', 'Gansu', 'Guizhou', 'Ningxia', 'Inner Mongolia', nan,\n",
       "       'Xinjiang', 'Jilin', 'Hong Kong', 'Taiwan', 'Qinghai', 'Macau',\n",
       "       'New South Wales', 'Victoria', 'Queensland', 'Ontario',\n",
       "       'Chicago, IL', 'South Australia', 'British Columbia', 'Tibet',\n",
       "       'Boston, MA', 'Los Angeles, CA', 'Orange, CA', 'Santa Clara, CA',\n",
       "       'Seattle, WA', 'Tempe, AZ', 'San Benito, CA', 'Toronto, ON',\n",
       "       'London, ON', 'Madison, WI', 'Cruise Ship',\n",
       "       'Diamond Princess cruise ship', 'San Diego County, CA',\n",
       "       'San Antonio, TX', 'Ashland, NE', 'Travis, CA',\n",
       "       'From Diamond Princess', 'Lackland, TX', 'Humboldt County, CA',\n",
       "       'Sacramento County, CA', 'Omaha, NE', 'Unassigned Location',\n",
       "       ' Montreal, QC', 'Western Australia', 'Portland, OR',\n",
       "       'Snohomish County, WA', 'Providence, RI', 'King County, WA',\n",
       "       'Cook County, IL', 'Tasmania', 'Grafton County, NH',\n",
       "       'Hillsborough, FL', 'New York City, NY', 'Placer County, CA',\n",
       "       'San Mateo, CA', 'Sarasota, FL', 'Sonoma County, CA',\n",
       "       'Umatilla, OR', 'Fulton County, GA', 'Washington County, OR',\n",
       "       ' Norfolk County, MA', 'Berkeley, CA', 'Maricopa County, AZ',\n",
       "       'Wake County, NC', 'Westchester County, NY', 'Orange County, CA',\n",
       "       'Northern Territory', 'Contra Costa County, CA',\n",
       "       'Bergen County, NJ', 'Harris County, TX',\n",
       "       'San Francisco County, CA', 'Clark County, NV',\n",
       "       'Fort Bend County, TX', 'Grant County, WA', 'Queens County, NY',\n",
       "       'Santa Rosa County, FL', 'Williamson County, TN',\n",
       "       'New York County, NY', 'Unassigned Location, WA',\n",
       "       'Montgomery County, MD', 'Suffolk County, MA', 'Denver County, CO',\n",
       "       'Summit County, CO', 'Calgary, Alberta', 'Chatham County, NC',\n",
       "       'Delaware County, PA', 'Douglas County, NE', 'Fayette County, KY',\n",
       "       'Floyd County, GA', 'Marion County, IN', 'Middlesex County, MA',\n",
       "       'Nassau County, NY', 'Norwell County, MA', 'Ramsey County, MN',\n",
       "       'Washoe County, NV', 'Wayne County, PA', 'Yolo County, CA',\n",
       "       'Santa Clara County, CA', 'Grand Princess Cruise Ship',\n",
       "       'Douglas County, CO', 'Providence County, RI',\n",
       "       'Alameda County, CA', 'Broward County, FL', 'Fairfield County, CT',\n",
       "       'Lee County, FL', 'Pinal County, AZ', 'Rockland County, NY',\n",
       "       'Saratoga County, NY', 'Edmonton, Alberta',\n",
       "       'Charleston County, SC', 'Clark County, WA', 'Cobb County, GA',\n",
       "       'Davis County, UT', 'El Paso County, CO', 'Honolulu County, HI',\n",
       "       'Jackson County, OR ', 'Jefferson County, WA',\n",
       "       'Kershaw County, SC', 'Klamath County, OR', 'Madera County, CA',\n",
       "       'Pierce County, WA', 'Plymouth County, MA',\n",
       "       'Santa Cruz County, CA', 'Tulsa County, OK',\n",
       "       'Montgomery County, TX', 'Norfolk County, MA',\n",
       "       'Montgomery County, PA', 'Fairfax County, VA',\n",
       "       'Rockingham County, NH', 'Washington, D.C.',\n",
       "       'Berkshire County, MA', 'Davidson County, TN',\n",
       "       'Douglas County, OR', 'Fresno County, CA', 'Harford County, MD',\n",
       "       'Hendricks County, IN', 'Hudson County, NJ', 'Johnson County, KS',\n",
       "       'Kittitas County, WA', 'Manatee County, FL', 'Marion County, OR',\n",
       "       'Okaloosa County, FL', 'Polk County, GA', 'Riverside County, CA',\n",
       "       'Shelby County, TN', 'Spokane County, WA', 'St. Louis County, MO',\n",
       "       'Suffolk County, NY', 'Ulster County, NY',\n",
       "       'Unassigned Location, VT', 'Unknown Location, MA',\n",
       "       'Volusia County, FL'], dtype=object)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Province/State'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hubei', 'Zhejiang', 'Guangdong', 'Henan', 'Hunan', 'Anhui',\n",
       "       'Jiangxi', 'Chongqing', 'Sichuan', 'Shandong', 'Jiangsu',\n",
       "       'Shanghai', 'Beijing', 'Fujian', 'Shaanxi', 'Guangxi', 'Hebei',\n",
       "       'Yunnan', 'Heilongjiang', 'Liaoning', 'Hainan', 'Shanxi',\n",
       "       'Tianjin', 'Gansu', 'Guizhou', 'Ningxia', 'Inner Mongolia', nan,\n",
       "       'Xinjiang', 'Jilin', 'Hong Kong', 'Taiwan', 'Qinghai', 'Macau',\n",
       "       'New South Wales', 'Victoria', 'Queensland', 'Ontario',\n",
       "       'Chicago, IL', 'South Australia', 'British Columbia', 'Tibet',\n",
       "       'Boston, MA', 'Los Angeles, CA', 'Orange, CA', 'Santa Clara, CA',\n",
       "       'Seattle, WA', 'Tempe, AZ', 'San Benito, CA', 'Toronto, ON',\n",
       "       'London, ON', 'Madison, WI', 'Cruise Ship',\n",
       "       'Diamond Princess cruise ship', 'San Diego County, CA',\n",
       "       'San Antonio, TX', 'Ashland, NE', 'Travis, CA',\n",
       "       'From Diamond Princess', 'Lackland, TX', 'Humboldt County, CA',\n",
       "       'Sacramento County, CA', 'Omaha, NE', 'Unassigned Location',\n",
       "       ' Montreal, QC', 'Western Australia', 'Portland, OR',\n",
       "       'Snohomish County, WA', 'Providence, RI', 'King County, WA',\n",
       "       'Cook County, IL', 'Tasmania', 'Grafton County, NH',\n",
       "       'Hillsborough, FL', 'New York City, NY', 'Placer County, CA',\n",
       "       'San Mateo, CA', 'Sarasota, FL', 'Sonoma County, CA',\n",
       "       'Umatilla, OR', 'Fulton County, GA', 'Washington County, OR',\n",
       "       ' Norfolk County, MA', 'Berkeley, CA', 'Maricopa County, AZ',\n",
       "       'Wake County, NC', 'Westchester County, NY', 'Orange County, CA',\n",
       "       'Northern Territory', 'Contra Costa County, CA',\n",
       "       'Bergen County, NJ', 'Harris County, TX',\n",
       "       'San Francisco County, CA', 'Clark County, NV',\n",
       "       'Fort Bend County, TX', 'Grant County, WA', 'Queens County, NY',\n",
       "       'Santa Rosa County, FL', 'Williamson County, TN',\n",
       "       'New York County, NY', 'Unassigned Location, WA',\n",
       "       'Montgomery County, MD', 'Suffolk County, MA', 'Denver County, CO',\n",
       "       'Summit County, CO', 'Calgary, Alberta', 'Chatham County, NC',\n",
       "       'Delaware County, PA', 'Douglas County, NE', 'Fayette County, KY',\n",
       "       'Floyd County, GA', 'Marion County, IN', 'Middlesex County, MA',\n",
       "       'Nassau County, NY', 'Norwell County, MA', 'Ramsey County, MN',\n",
       "       'Washoe County, NV', 'Wayne County, PA', 'Yolo County, CA',\n",
       "       'Santa Clara County, CA', 'Grand Princess Cruise Ship',\n",
       "       'Douglas County, CO', 'Providence County, RI',\n",
       "       'Alameda County, CA', 'Broward County, FL', 'Fairfield County, CT',\n",
       "       'Lee County, FL', 'Pinal County, AZ', 'Rockland County, NY',\n",
       "       'Saratoga County, NY', 'Edmonton, Alberta',\n",
       "       'Charleston County, SC', 'Clark County, WA', 'Cobb County, GA',\n",
       "       'Davis County, UT', 'El Paso County, CO', 'Honolulu County, HI',\n",
       "       'Jackson County, OR ', 'Jefferson County, WA',\n",
       "       'Kershaw County, SC', 'Klamath County, OR', 'Madera County, CA',\n",
       "       'Pierce County, WA', 'Plymouth County, MA',\n",
       "       'Santa Cruz County, CA', 'Tulsa County, OK',\n",
       "       'Montgomery County, TX', 'Norfolk County, MA',\n",
       "       'Montgomery County, PA', 'Fairfax County, VA',\n",
       "       'Rockingham County, NH', 'Washington, D.C.',\n",
       "       'Berkshire County, MA', 'Davidson County, TN',\n",
       "       'Douglas County, OR', 'Fresno County, CA', 'Harford County, MD',\n",
       "       'Hendricks County, IN', 'Hudson County, NJ', 'Johnson County, KS',\n",
       "       'Kittitas County, WA', 'Manatee County, FL', 'Marion County, OR',\n",
       "       'Okaloosa County, FL', 'Polk County, GA', 'Riverside County, CA',\n",
       "       'Shelby County, TN', 'Spokane County, WA', 'St. Louis County, MO',\n",
       "       'Suffolk County, NY', 'Ulster County, NY',\n",
       "       'Unassigned Location, VT', 'Unknown Location, MA',\n",
       "       'Volusia County, FL'], dtype=object)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Province/State'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
