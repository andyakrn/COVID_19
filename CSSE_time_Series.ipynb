{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>\n",
    "    Loading In Data\n",
    "    </center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "import os\n",
    "import pickle\n",
    "import base64\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath = 'data_csse/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"github.txt\") as myfile:\n",
    "    firstNlines=myfile.readlines()[0:2]\n",
    "myfile.close()\n",
    "g = Github(firstNlines[0].strip(), firstNlines[1])\n",
    "repo=g.get_repo('CSSEGISandData/COVID-19')\n",
    "contents = repo.get_contents(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sha_for_tag(repository, tag):\n",
    "    branches = repository.get_branches()\n",
    "    matched_branches = [match for match in branches if match.name == tag]\n",
    "    if matched_branches:\n",
    "        return matched_branches[0].commit.sha\n",
    "\n",
    "    tags = repository.get_tags()\n",
    "    matched_tags = [match for match in tags if match.name == tag]\n",
    "    if not matched_tags:\n",
    "        raise ValueError('No Tag or Branch exists with that name')\n",
    "    return matched_tags[0].commit.sha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_directory(repository, sha, server_path, local_path=mypath):\n",
    "    contents = repository.get_contents(server_path, ref=sha)\n",
    "    if not os.path.exists(local_path):\n",
    "        os.makedirs(local_path)\n",
    "    for content in contents:\n",
    "        if content.type == 'dir':\n",
    "            download_directory(repository, sha, content.path)\n",
    "        else:\n",
    "            try:\n",
    "                path = content.path\n",
    "                file_content = repository.get_contents(path, ref=sha)\n",
    "                file_data = base64.b64decode(file_content.content).decode('ascii')\n",
    "                file_out = open(local_path+content.name, \"w\")\n",
    "                file_out.write(local_path+file_data)\n",
    "                file_out.close()\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_non_zero_file(fpath):\n",
    "    return os.path.isfile(fpath) and os.path.getsize(fpath) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df, name):\n",
    "    df.drop(columns=['data_csse/Province/State', 'Lat', 'Long'], inplace=True)\n",
    "    df = df.groupby(['Country/Region']).agg('sum')\n",
    "    df = df.transpose().reset_index()\n",
    "    country_list = list(df.columns)[1:]\n",
    "    df = pd.melt(df, id_vars='index', value_vars=country_list)\n",
    "    df = df.rename(columns={'index':'Date', 'value':name})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sha = get_sha_for_tag(repo, 'master')\n",
    "download_directory(repo, sha, 'csse_covid_19_data/csse_covid_19_time_series/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "# timeseries_files = []\n",
    "# for file in onlyfiles:\n",
    "#     if is_non_zero_file(mypath + file) and file[-10:]=='global.csv':\n",
    "#         timeseries_files.append(mypath + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_df = pd.read_csv('data_csse/time_series_covid19_confirmed_global.csv')\n",
    "deaths_df = pd.read_csv('data_csse/time_series_covid19_deaths_global.csv')\n",
    "recovered_df = pd.read_csv('data_csse/time_series_covid19_recovered_global.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_df = preprocess_df(confirmed_df, 'Confirmed')\n",
    "deaths_df = preprocess_df(deaths_df, 'Deaths')\n",
    "recovered_df = preprocess_df(recovered_df, 'Recovered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>\n",
    "    Preprocessing Data\n",
    "    </center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confirmed_and_deaths = pd.merge(confirmed_df, deaths_df, how='inner', on=['Date', 'Country/Region'])\n",
    "grouped_df = pd.merge(confirmed_and_deaths, recovered_df, how='inner', on=['Date', 'Country/Region'])\n",
    "grouped_df['Active'] = grouped_df['Confirmed']-grouped_df['Deaths']-grouped_df['Recovered']\n",
    "grouped_df['Datetime'] = grouped_df['Date'].apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = pd.read_csv('pop_df4.csv')\n",
    "pop_df['Country/Region'] = pop_df['Country/Region'].apply(lambda x: x.replace('Mainland China', 'China'))\n",
    "pop_df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list=[('Mainland China', 'China'),\n",
    "('Hong Kong SAR', 'Hong Kong'),\n",
    "(['Korea, South', 'Republic of Korea'], 'South Korea'),\n",
    "('United Kingdom', 'UK'),\n",
    "(['Taiwan*', 'Taipei and environs'], 'Taiwan'),\n",
    "('Iran (Islamic Republic of)', 'Iran'),\n",
    "('Viet Nam', 'Vietnam'),\n",
    "('Macao SAR', 'Macau'),\n",
    "('Republic of Ireland', 'Ireland'),\n",
    "('Czechia', 'Czech Republic'),\n",
    "('occupied Palestinian territory', 'Palestine'),\n",
    "('Russian Federation', 'Russia'),\n",
    "(' Azerbaijan', 'Azerbaijan'),\n",
    "('Holy See', 'Vatican City'),\n",
    "('Republic of Moldova', 'Moldova'),\n",
    "('Saint Martin', 'St. Martin')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in country_list:\n",
    "    grouped_df['Country/Region']=grouped_df['Country/Region'].replace(name[0],name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'PopTotal' in set(grouped_df.columns):\n",
    "    grouped_df = pd.merge(grouped_df, pop_df, on='Country/Region')\n",
    "grouped_df['Confirmed Cases Per 1M'] = grouped_df['Confirmed']*1000/grouped_df['PopTotal']\n",
    "grouped_df['Country/Region'] = grouped_df['Country/Region'].str.replace('US', 'United States')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>\n",
    "    Export Dataframe\n",
    "    </center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('COVID_Hopkins_df.pickle', 'wb') as pickle_out:\n",
    "    pickle.dump(grouped_df, pickle_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
